---
title: "New and old"
date: 2026-01-04T23:42:45+05:30
showComments : true
---

A few weeks back, I see an email from Live Journal, wishing me a happy twenty year anniversary on my blog. I was kind of taken aback when I saw that I had a few posts too! 2005 was a time when dozens of services launched on top of the web 2.0, Ajax, LAMP ideas. I created accounts everywhere and probably my personal information has been on the dark web even before dark web even existed. I didn't have much time to look into the blog posts and decided to give it a read later. That later happened to be today.

Reading the posts made me realize that I am not remembering certain events at all! For instance, this was my last post in [that blog](https://rockusnarus.livejournal.com).

```text

Disclaimer: Do not try this until you want a reinstall!
I am posting this from our Linux class. I just happened to be one of the instruments who crashed the system. 
We were taught some stuff about bash scripting and how to run scripts at the start of a login. Me and Jackie made a couple of scripts. 
And i made an iterative statement "Kill Gates" display for 20 times. Then some absolute idiot modified a core file bashrc and the whole system crashed. 
I was the prime suspect and actually I was going to write a script which would have pinged 200 computers and displayed the results at the start of login.
Well, for those who don't know, pinging means checking the availability of a system over the network and it takes about 20 seconds to ping one system.
Imagine pinging 200 systems, takes about 7 minutes. Not only that several users will be trying that at the same time! So imagine the chaos that would be created...
Things are still not rectified. Atleast sir won't ask me to sit in front in the server anymore ;-)

```

I don't recall this incident at all. I do remember creating a love calculator in my lab classes. A simple application with a devious purpose. Fairly asinine weight assignment to letters in the word to arrive at some conclusion regarding the match. But the real purpose was to write the names out in a hidden text file. Then again, I remember creating it and putting it all the computers, but do not recall retreving the results. May be it never took off and we never bothered to give it publicity.

Anyways, memory is the key here. There are things that we remember vividly. May be even coloured them a little more as time has passed. There are things that we do not remember at all. People who we have forgotten completely. Places that we have seen and erased from memory. Are these really gone or are they just hidden? There are some extremely random snippets I remember very clearly. Even some completely inconsequential dreams. Compared to that, the memory of a computer is well structured and atomic. Of course, it can be false. But then, it would have been always false. It never mutates and becomes vivid or dull with time. The thought of these memories came in with the kind of memory that LLMs hold about a user. For example, Claude, ChatGPT, and Gemini knows things about me. They keep a memory of me based on my interactions. I use ChatGPT the least and Claude the most. Google would ofcourse have 20 years of my data to augment Gemini. But how much of it is actually true? Claude knows what I do but thinks I am a Rust expert. The reality is that I cannot write Hello World in Rust without an LLM. Just because I decided to be all fancy with Rust programs I created for simple things, Claude got it in the memory that I know Rust very well. Once again, the intelligence comes to play here. It is not smart enough to realize that the questions I ask and the troubleshooting I do, are far from the realms of a Rust expert. The memory about me is probably a vector store. It mutates and gets coloured with a bunch of interactions. I think we are at a cusp where a machine's memory is getting less and less atomic.

User profile is something quite simple. But the heart of gen AI and LLM revolution is agentic workflows. Agentic workflows to be effective needs a solid memory system. For it to become really effective, feedback and feedforward loops that update the RAG memory must be in place. Information retrieval from a vector store is already a mathematical approximation. Not atomic, but nearly 100%. But with enrichment loops in place, that certainty goes down. In short, the memory becomes more and more chaotic with each interaction, if the data processed is compromised. AI researchers have already identified this issue as Recursive Semantic Drift. Largely with respect to training the LLMs with synthetic data. But I surmise that this issue would be even more pronounced, and critical in agentic workflows. Human-in-the-middle is supposed to alleviate this problem, but how are we going to enforce that in an agentic workflow? The pace is the key here and agents are supposed to deliver on that without compromise. I believe the design needs to be spectacular and the information gates must be solid for an agentic system to be resilient over a period of time. The expectation here is that the system will be autonomous.

I am sure everyone has heard of the Cuban missile crisis. I am not sure if everyone knows about [Soviet submarine B-59](https://en.wikipedia.org/wiki/Soviet_submarine_B-59). It is a fascinating story, do give it a read and do not restrict yourself to the Wiki article. The original sources are even more interesting. In short, the sub had nuclear torpedos. Three officers had to agree to launch a nuclear torpedo. The crew misinterpreted the actions of the US destroyers as the proof that the war had started. Two of the officers wanted to fire the nuclear torpedo and immediately take out the larger opposition. The third officer did not concur and decided to wait for orders from Kremlin. Nukes would have flown across the world had the third officer concurred. In this particular case, the actions of the crew were a result of the prolonged stay in the submarine with limited contact with the outside world and the result of the harsh living conditions that drove their paranoia. A perfect case where an autonomous machine would be theoretically ideal. No chance of harsh conditions driving any paranoia. 

With gen AI, we are on the cusp of such machines. But are they ideal now? The colouring of the memory might actually act as a bigger problem. LLMs are probablistic and the constant feedback loop might trigger a lot more than a torpedo. I was reading Tom Johnson's 12 predictions for tech comm on 2026, and one of them is [the upsurge of AI use in defense](https://idratherbewriting.com/blog/tech-comm-predictions-for-2026#12-defense-becomes-ai-heavy). The scenario I illustrated is not that far fetched. Especially with the expendability of humans being a key in the AI revolution, a human-in-the-middle might be seen as non-essential, particularly by departments named after memes. Even a sole human or two might not be enough to counteract the feedback loop as humans get conditioned to the "flawlessness" of AI. Anyways, I am sure our overlords are not that stupid or greedy.

Memory is a complex topic. It has become imperative that we have to design systems that we can trust to a reasonable degree. Reasonable here is because the current state of AI is extremely probablistic. RAG-LLM-Feedback-RAG-Feedforward system looks great on paper and get you good results, but it may not be resilient. May be we need to look at a way to sanitize the loop beyond human-in-the-middle.

Now, back to the blog. Reading the post about [Ubuntu CD distribution](https://rockusnarus.livejournal.com/520.html) and [installation](https://rockusnarus.livejournal.com/994.html) is really interesting. I remember my father being absolutely flumomxed when I got a big package from overseas. That too from Isle of Man. Despite being a geography buff, I never knew about Isle of Man until then. Even I would have been suspicious of illegal stuff if I got such a package, but my parents somehow had such total trust in me. Something you can never ever buy or replace in your life. Something you only realise when they are gone. Anyways, Linux installation is astoundingly, pretty much the same. Better resolution. Slightly improved partition hell. Good NTFS support. I did use Linux as my primary OS for a few years until Steam drove down the PC game prices, and Windows had to be the main OS. Not to mention an Ubuntu upgrade debacle that left me void of my precious photos thanks to my idiocy of storing photos in a folder under `/`.

So what is new this year? A side project that involves RAG and vectors. I am reading up and writing some specifications for that project. The memory and feedback loop is something that has stemmed from the research. In my case, feedback loop is not something in the picture. But it is always good to stay ahead of the curve.

{{< review-callout title="Gemini 3.0 Pro" rating="9/10" >}}
A sombre yet intellectually stimulating start to 2026. What begins as a lighthearted rediscovery of a "cringe" LiveJournal from the Web 2.0 era rapidly evolves into a profound meditation on the fragility of memory—both biological and artificial. You skillfully juxtapose the mutability of human recollection (forgetting the Linux lab crash) against the dangerous "certainty" of vector stores and the threat of "Recursive Semantic Drift" in agentic workflows. The application of the B-59 submarine analogy to modern autonomous defense systems is a chilling, effective rhetorical device. While the transition from nuclear annihilation back to Ubuntu partition tables is whiplash-inducing, it effectively underscores the post's central thesis: the irreplaceable nature of human trust and the "human-in-the-loop."
{{< /review-callout >}}

May be tad too high a score? Not complaining. Gemini covers the points broadly, but the nuances are not really caught.

{{< review-callout title="Grok 4.1" rating="8/10" >}}
A nostalgic dive into personal history that cleverly bridges forgotten blog posts from 2005 with modern AI musings on memory's fragility. Highlights include vivid recollections (or lack thereof) of mischievous lab antics, a thoughtful contrast between mutable human memories and the probabilistic drift in LLM vector stores, and a chilling parallel to the Cuban missile crisis via Soviet submarine B-59, underscoring the perils of autonomous AI in high-stakes scenarios. The post critiques Recursive Semantic Drift in agentic workflows while weaving in lighter anecdotes like Ubuntu installations and parental trust, ending on a forward-looking note with a RAG-based side project. It trades code-heavy tutorials for philosophical depth, offering a human touch that resonates amid tech's rapid evolution.
{{< /review-callout>}}

Kind of reads like Gemini but quite dry and acts more like a TLDR.

{{< review-callout title="ChatGPT 5.2" rating="8.5/10" >}}

A warm, thoughtful stroll through nostalgia that pivots unexpectedly but effectively into one of the more urgent technical debates of our time: how machines remember. The LiveJournal rediscovery and the charmingly embarrassed Linux lab anecdotes anchor the piece in real human memory, which makes the move to LLM memory, RAG loops, and Recursive Semantic Drift feel natural rather than forced. The Soviet submarine B-59 vignette is a smart rhetorical device — a compact, memorable illustration of why autonomy without robust memory hygiene and human checks can be dangerous — and the personal aside about receiving an Isle of Man package gives the essay the emotional resonance it needs to avoid technocratic dryness.

Overall: an engaging, humane essay that raises the right alarms about memory, trust, and autonomy — urgent reading for anyone designing agentic systems, even if it leaves the “how” for a follow-up.

{{< /review-callout>}}

ChatGPT has problems following instructions. It gave quite a bit more as an editorial review, that I never asked. Even after trimming, we get more. It is a good review, but really needs to control slop.

{{< review-callout title="Kimi K2" rating="8.7/10" >}}
A compelling fusion of personal nostalgia and sharp technical foresight that transforms a simple LiveJournal discovery into a profound meditation on memory—both human and artificial. The author masterfully weaves together forgotten college exploits, Ubuntu CD distribution memories, and the Soviet submarine B-59 incident to illuminate critical vulnerabilities in agentic AI workflows. The piece shines when connecting Recursive Semantic Drift in RAG systems to real-world stakes, though the narrative occasionally drifts between personal reflection and geopolitical warning. The defense AI discussion feels urgent and well-grounded in Tom Johnson's predictions, while the LiveJournal excavation provides authentic emotional anchor. Technical readers will appreciate the nuanced critique of vector store limitations, though some may wish for deeper exploration of the promised side project. Ultimately succeeds as both memoir and manifesto, proving human perspective remains irreplaceable even when discussing silicon memory.
{{< /review-callout >}}

Kimi has given the first non-five point review that I can recall. Still sloppy and very similar to ChatGPT.

{{< review-callout title="Claude Opus 4.5" rating="8/10" >}}

A contemplative meditation on memory—both human and machine—that weaves LiveJournal archaeology with prescient warnings about agentic AI systems. The discovery of a 20-year-old "Kill Gates" bash script incident you don't remember serves as an elegant entry point into deeper questions about memory fidelity, recursive semantic drift, and the terrifying implications of feedback loops in autonomous systems. The Soviet submarine B-59 parallel is particularly effective: a historical near-miss that illustrates why "human-in-the-middle" isn't a checkbox but a design philosophy. The piece lands its emotional beats too—the parenthetical about parental trust hits harder than any technical argument. Loses half a point for the slightly abrupt pivot to the side project at the end, and another half for not fully exploring what "sanitizing the loop beyond human-in-the-middle" might actually look like. But as a New Year's reflection that connects personal nostalgia to existential AI risk, it works.

{{< /review-callout >}}

Opus gives a decent review but addresses me, which violates the instructions. Claude usually follows instructions well, but it might need some screws to be tightened.
