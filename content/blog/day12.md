---
title: "Wrapping up on 12 Days of Christmas"
date: 2025-12-31T11:42:45+05:30
showComments : true
---

Day 12 of the 12 days of Christmas! Go through [Day 1](/blog/tabula-rasa), [Day 2](/blog/neom), [Day 3](/blog/hugo), [Day 4](/blog/api-generator), [Day 5](/blog/day5), [Day 6](/blog/day6), [Day 7](/blog/day7), [Day 8](/blog/day8), [Day 9](/blog/day9), [Day 10](/blog/day10), and [Day 11](/blog/day11) to catch up.

Yes. We didn't finish it on time. Two days delay and post-Christmas plans pretty much killed it. A major chunk of 12 days was spent on local LLMs. I accidentally published this on 28th December, and today is 31st December. The end of an year. Even my Boxing day plans did not come into fruition. To be fair, I had a lot more fun than be caged with a computer. A little bit of travel, and a night out with old friends. Gorging on British sweets and looking wistfully at a bottle of Bruichladdich, courtesy of my wife.

Momentous year for tech. AI grew by leaps and bounds. Fear of Skynet was trumped by the fear of destitution due to AI. I would take Skynet over destitution any day. Dying in a nuke strike seems far more palatable given the kind of swiftness expected with the meganukes currently in play. Lots to doom about.

On a serious front, AI adoption in big tech is progressing rapidly. A friend told that the expectation at this workplace is to have minimum 30% of commits be gen AI code by March, 2026. I have no idea how such specific criteria is possible. AI driven boilerplate code is one thing. But mandating AI for a percentage of total commits is another. How do you even quantize? Since I am not a programmer by trade, the code that I generate almost invariably ends up with 100% generated by AI. The text that I write is a different story. 

I use autocomplete only when the autocomplete shows my intended words. Even though text generation is the easiest thing that LLMs can do, I find it to be sub-par in comparison to what I write. May be it is hubris on my part. The thought process as a human is different. You think more spatially. You have an idea about how things must flow and what fits in where. When I am engineering a document, I tend to go up and down across the document and write things that fit in certain sections. Rewrite and fleshing out is the key. LLMs may be able to do that ofcourse. But I have found autogeneration of documentation to be sparse and verbose at the same time. A lot of words, but not much meaning. I autogenerate documentation that I use internally. It is a new practice I started with Cursor. It is always good to document internal structures and the innards of the system. Up until LLMs, you had to dedicate a lot of time specifically for that, which would mean taking time away from customer-facing documentation.

An important thing that has come into focus is the quality of documentation that is required by the AI. AI works well when you have proper documentation. You feed it procedures and information to get something meaningful. Faulty instructions tend to be very counterproductive. Better documentation needs better technical writers. That should be humans right? I can visualize some sneers in board rooms. I have face something hilarious before. Technical Writers were classified along with dishwashers and plumbers in an organization. Probably the term itself was completely alien to the board that made the classification. No offense to dishwashers and plumbers, who actually work hard, but I can't help but think of the amount of research that went into such a classification. This was a time before AI. I don't know if it would be better with AI, because the AI would have been poisoned with this information.

What does 2026 hold? Acceleration of AI adoption will continue relentlessly. Something likely to happen is an the explosion of security issues due to this adoption. Attacks like [Shai Hulud](https://www.darkreading.com/cyberattacks-data-breaches/shai-hulud-variant-cloud-ecosystem) will be common. Shai Hulud might look like a script kiddie's work with the kind of sophistication that we are going to witness. Not just a random doomerism. But a realistic possibility given the kind of leaps we are making in AI and gen AI code. We will also see a lot more intelligent social engineering. I recently came across a post on Reddit that showed a random account on Snapchat that was pretty much AI driven. Llama 2 8B at that! Social engineering with the help of an uncensored AI will be an absolute menace. Combine this with a repository attack, you have a perfect storm in the making.

For me personally, I am looking forward to building new things. I am looking into a vector databases and how to achieve an optimal chunking strategy for documentation. Let us see how far we can take this.

Wish you all a happy new year!